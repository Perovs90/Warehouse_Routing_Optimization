{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkh5GyU-iXQe"
   },
   "source": [
    "## Mounting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHnhQtvdU5Dv",
    "outputId": "313ccf06-3a8e-4cca-f05e-8813a0164b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGDvzBLiihCR"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "oJCb_eS-Zws0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/AN')\n",
    "import pandas as pd\n",
    "import rafs_instance as instance\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "from lxml import etree\n",
    "import pdb\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from itertools import groupby \n",
    "from random import randint\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NkK-Uxeimbb"
   },
   "source": [
    "# Loading data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "SnVQL7C39yJz"
   },
   "outputs": [],
   "source": [
    "# Specify version of order (\"\", \"_a\" or \"_b\")\n",
    "orderVersion = \"_a\"\n",
    "\n",
    "# Specify mean item amount in an order (either 1x6 or 5)\n",
    "meanItemInOrder = \"5\"\n",
    "\n",
    "# Specify the number of orders we receive (either 10 or 20)\n",
    "orderAmount = 20\n",
    "\n",
    "# Specify the number of items in the warehouse (either 24 or 360)\n",
    "itemAmount = 360\n",
    "\n",
    "# SPecifiy the pod amount\n",
    "podAmount = 360\n",
    "\n",
    "# Specify the policy (either \"dedicated_1\" or \"mixed_shevels_1-5\")\n",
    "podPolicy = \"dedicated_1\"\n",
    "\n",
    "#%% A) importing files and creating instances defined in instance_demo.py\n",
    "\n",
    "#All files required for SKU24 and SKU360\n",
    "layoutFile = r'/content/drive/MyDrive/AN/data/layout/1-1-1-2-1.xlayo'\n",
    "\n",
    "# loading all the information about the pods\n",
    "podInfoFile = '/content/drive/MyDrive/AN/data/sku' + str(itemAmount) + '/pods_infos.txt'   \n",
    "# loading information about picking locations, packing stations, waypoints,\n",
    "# pods \n",
    "instances = {}\n",
    "instances[itemAmount,2] = r'/content/drive/MyDrive/AN/data/sku' + str(itemAmount) + '/layout_sku_' + str(itemAmount) + '_2.xml'\n",
    "instanceFile = r'data/sku' + str(itemAmount) + '/layout_sku_' + str(itemAmount) + '_2.xml'\n",
    "\n",
    "storagePolicies = {}\n",
    "# loading information about item storage: contains all SKUs along with their\n",
    "# attributes\n",
    "storagePolicies['dedicated'] = '/content/drive/MyDrive/AN/data/sku' + str(itemAmount) + '/pods_items_' + str(podPolicy) + '.txt'\n",
    "#storagePolicies['mixed'] = 'data/sku24/pods_items_mixed_shevels_1-5.txt'\n",
    "\n",
    "# loading information about the orders: contains list of orders, with number\n",
    "# of ordered items per SKU-ID\n",
    "orders = {}\n",
    "orders[str(orderAmount)+\"_\"+ str(meanItemInOrder)] =r'/content/drive/MyDrive/AN/data/sku' + str(itemAmount) + '/orders_' + str(orderAmount) + '_mean_' + str(meanItemInOrder) + '_sku_' + str(itemAmount) + orderVersion + '.xml'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H-G20ZLO7Ry"
   },
   "source": [
    "# Data Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeUT8jV7TlEk",
    "outputId": "798f21dc-e40b-4494-b2f5-93810fade5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] preparing all data with the standard format: \n",
      "[1] changing data format for the algorithm we used here: \n",
      "preprocessingFilterPods\n",
      "d_ij file /content/drive/MyDrive/AN/data/distances/layout_sku_360_2.json loaded\n"
     ]
    }
   ],
   "source": [
    "class WarehouseDateProcessing():\n",
    "    def __init__(self, warehouseInstance, batch_size = None):\n",
    "        self.Warehouse = warehouseInstance # the link to the .py file\n",
    "        self._InitSets(warehouseInstance, batch_size) # creates V as a dict with output station and item lists based on color and letter for each order   \n",
    "        \n",
    "    def preprocessingFilterPods(self, warehouseInstance):\n",
    "        \n",
    "        resize_pods = {}\n",
    "        print(\"preprocessingFilterPods\")\n",
    "        item_id_list=[]\n",
    "        for order in warehouseInstance.Orders:\n",
    "            for pos in order.Positions.values():\n",
    "                item = warehouseInstance.ItemDescriptions[pos.ItemDescID].Color.lower() + '/' + warehouseInstance.ItemDescriptions[pos.ItemDescID].Letter\n",
    "\n",
    "                if item not in item_id_list:\n",
    "                    item_id_list.append(item)\n",
    "                \n",
    "\n",
    "        # for dedicated\n",
    "        for pod in warehouseInstance.Pods.values():\n",
    "            for item in pod.Items:\n",
    "                if item.ID in item_id_list:\n",
    "                    resize_pods[pod.ID] = pod\n",
    "\n",
    "        return resize_pods\n",
    "\n",
    "    # Initialize sets and parameters           \n",
    "    def _InitSets(self,warehouseInstance, batch_size):\n",
    "        #V Set of nodes, including shelves V^S and stations (depots)\n",
    "        # V^D (V=V^S U V^D)\n",
    "        #Add output and input depots\n",
    "        \n",
    "        self.V__D__C = warehouseInstance.OutputStations\n",
    "        self.V__D__F = {}\n",
    "\n",
    "             \n",
    "        self.V__D = {**self.V__D__C, **self.V__D__F}\n",
    "\n",
    "        self.V__S = self.preprocessingFilterPods(warehouseInstance)\n",
    "        \n",
    "        #Merge dictionaries\n",
    "        self.V = {**self.V__D, **self.V__S}\n",
    "\n",
    "    def CalculateDistance(self):\n",
    "\n",
    "        file_path = r'/content/drive/MyDrive/AN/data/distances/' + os.path.splitext(os.path.basename(self.Warehouse.InstanceFile))[0] + '.json'\n",
    "        if not path.exists(file_path):\n",
    "            #Create d_ij\n",
    "            d_ij = {}\n",
    "            for key_i, node_i in self.V.items():\n",
    "                for key_j, node_j in self.V.items():  \n",
    "                    \n",
    "                    source = 'w'+node_i.GetPickWaypoint().ID\n",
    "                    target = 'w'+node_j.GetPickWaypoint().ID\n",
    "                    \n",
    "                    #Calc distance with weighted shortest path\n",
    "                    d_ij[(key_i,key_j)] = nx.shortest_path_length(self.Graph, source=source, target=target, weight='weight')\n",
    "            \n",
    "            #Parse and save\n",
    "            d_ij_dict = {}\n",
    "            for key,value in d_ij.items():\n",
    "                i,j = key  \n",
    "                if i not in d_ij_dict:\n",
    "                    d_ij_dict[i]={} \n",
    "                d_ij_dict[i][j] = value\n",
    "            \n",
    "            with open(file_path, 'w') as fp:\n",
    "                json.dump(d_ij_dict, fp)\n",
    "        \n",
    "        else: \n",
    "            #Load and deparse\n",
    "            with open(file_path, 'r') as fp:\n",
    "                d_ij_dict = json.load(fp)\n",
    "            print('d_ij file %s loaded'%(file_path)) \n",
    "                \n",
    "            #d_ij = tupledict()\n",
    "            d_ij = {}\n",
    "            for i, values in d_ij_dict.items():\n",
    "                for j, dist in values.items():\n",
    "                    d_ij[i,j] = dist                \n",
    "                \n",
    "        return d_ij\n",
    "\t\t\n",
    "\n",
    "class Demo():\n",
    "    def __init__(self, splitOrders = False):\n",
    "        \n",
    "        self.batch_weight = 18\n",
    "        self.item_id_pod_id_dict = {}\n",
    "        #[0]\n",
    "        self.warehouseInstance = self.prepareData()\n",
    "        self.distance_ij = self.initData()\n",
    "        #[2]\n",
    "        if storagePolicies.get('dedicated'):\n",
    "            self.is_storage_dedicated = True\n",
    "        else:\n",
    "            self.is_storage_dedicated = False\n",
    "\n",
    "\n",
    "\t# warehouse instance\n",
    "    def prepareData(self):\n",
    "        print(\"[0] preparing all data with the standard format: \")\n",
    "        #print(instances)\n",
    "        #Every instance\n",
    "        for key,instanceFile in instances.items():\n",
    "          # the key is the previously defined tuple in instances\n",
    "          # the instanceFile is the XML path\n",
    "            #print(instanceFile)\n",
    "            podAmount = key[0]\n",
    "            depotAmount = key[1] \n",
    "            #For different orders\n",
    "            for key, orderFile in orders.items():\n",
    "              # the key is the previously defined tuple in orders\n",
    "                orderAmount = key\n",
    "                #For storage policies\n",
    "                for storagePolicy, storagePolicyFile in storagePolicies.items(): # what item in what pod   \n",
    "                    warehouseInstance = instance.Warehouse(layoutFile, instanceFile, podInfoFile, storagePolicyFile, orderFile)\n",
    "        return warehouseInstance\n",
    "\n",
    "\t# distance\n",
    "    def initData(self):\n",
    "        print(\"[1] changing data format for the algorithm we used here: \")\n",
    "        warehouse_data_processing = WarehouseDateProcessing(self.warehouseInstance)\n",
    "        #Distance d_ij between two nodes i,j \\in V\n",
    "        d_ij = warehouse_data_processing.CalculateDistance()\n",
    "        return d_ij\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _demo = Demo()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJRYnGEihenb"
   },
   "source": [
    "# Greedy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zDwgRMzsdqU"
   },
   "source": [
    "## Distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "6qMEwdq1sZXy"
   },
   "outputs": [],
   "source": [
    "distances = _demo.distance_ij\n",
    "\n",
    "packing_stations = list(_demo.warehouseInstance.OutputStations.keys()) # getting the packing stations as dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWbXr6qTtHLY"
   },
   "source": [
    "## Data extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "E5-iprqlbU4Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "# to extract the dict of all locations in an order\n",
    "def extract_order_positions(order):\n",
    "  return list(order.Positions.keys())\n",
    "\n",
    "\n",
    "# to extract all the weights of the items inside an order\n",
    "def extract_order_weight(order, ItemDescriptions = _demo.warehouseInstance.ItemDescriptions):\n",
    "  total_weight = 0\n",
    "  for pos in order.Positions.values():\n",
    "    total_weight += ItemDescriptions[pos.ItemDescID].Weight * float(pos.Count)\n",
    "  return total_weight\n",
    "\n",
    "def extract_order_letter_color(order, ItemDescriptions = _demo.warehouseInstance.ItemDescriptions): \n",
    "  # color_letter = {}\n",
    "  item_id_list = []\n",
    "  for pos in order.Positions.values():\n",
    "    item = ItemDescriptions[pos.ItemDescID].Color.lower() + '/' + ItemDescriptions[pos.ItemDescID].Letter\n",
    "    # color_letter[order] = item\n",
    "    if item not in item_id_list:\n",
    "      item_id_list.append(item)\n",
    "        # print(item_id)\n",
    "  return item_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyXhhazM22i1",
    "outputId": "b193ad7d-4b5e-4cf6-9dd9-8ea223be6b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rafs_instance.Order at 0x7f95f0cf3690>,\n",
       " <rafs_instance.Order at 0x7f95f0cf3610>,\n",
       " <rafs_instance.Order at 0x7f95f0cf3590>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1dd0>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1c50>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1d10>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1850>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1450>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1ad0>,\n",
       " <rafs_instance.Order at 0x7f95f0cf1950>,\n",
       " <rafs_instance.Order at 0x7f95f0cf03d0>,\n",
       " <rafs_instance.Order at 0x7f95f0cf02d0>,\n",
       " <rafs_instance.Order at 0x7f95f0cf0ad0>,\n",
       " <rafs_instance.Order at 0x7f95f0cf0d90>,\n",
       " <rafs_instance.Order at 0x7f95f0cec9d0>,\n",
       " <rafs_instance.Order at 0x7f95f0cec150>,\n",
       " <rafs_instance.Order at 0x7f95f0cecb10>,\n",
       " <rafs_instance.Order at 0x7f95f0cecad0>,\n",
       " <rafs_instance.Order at 0x7f95f0cecd90>,\n",
       " <rafs_instance.Order at 0x7f95f0d5d1d0>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_list = _demo.warehouseInstance.Orders\n",
    "orders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "RdZHjosu0X7G"
   },
   "outputs": [],
   "source": [
    "#we need to create a nested dictionary: orders -> Item ID -> shelve ID\n",
    "# 1) we can get order - > item ID(position) -> letter/color\n",
    "# 2) get letter/color -> pod ID (from warehouseInstance.Pods)\n",
    "# 3)combine 1 and 2 to get order -> item ID -> pod ID\n",
    "\n",
    "#from this dictionary we can extract list of all ID for items of orders\n",
    "def get_order_item_ID(orders = orders_list):\n",
    "  order_item_ID = {}\n",
    "  for order in orders:\n",
    "    order_item_ID[order] = extract_order_positions(order)\n",
    "  return order_item_ID\n",
    "\n",
    "#from this dictionary we can extract list of all color/letter for items of orders\n",
    "def get_order_item_letter_color(orders = orders_list, ItemDescriptions = _demo.warehouseInstance.ItemDescriptions):\n",
    "  order_item_letter_color = {}\n",
    "  for order in orders:\n",
    "    order_item_letter_color[order] = extract_order_letter_color(order, ItemDescriptions)\n",
    "  return order_item_letter_color\n",
    "\n",
    "\n",
    "\n",
    "#create nested dictionary orders -> item ID -> letter/color\n",
    "def get_order_itemID_letter_color(orders = orders_list):\n",
    "  orders_item_ID = get_order_item_ID(orders)\n",
    "  order_item_letter_color = get_order_item_letter_color(orders = orders)\n",
    "  order_itemID_item_letter_color = {}\n",
    "  for order in orders:\n",
    "    order_itemID_item_letter_color[order] = dict(zip(orders_item_ID[order], order_item_letter_color[order]))       \n",
    "  return order_itemID_item_letter_color\n",
    "\n",
    "\n",
    "#create dictionary podID -> letter/color\n",
    "#the dictionary will be valid for mix shelve policy too\n",
    "# contains item ID and description for the items stored in each pod\n",
    "def get_podID_pod_letter_color(pods_dict = _demo.warehouseInstance.Pods):\n",
    "  podID_pod_letter_color = defaultdict(list)\n",
    "  for podID, pod in pods_dict.items():\n",
    "    for item in pod.Items:\n",
    "      podID_pod_letter_color[podID] +=  [item.ID]\n",
    "  return podID_pod_letter_color\n",
    "\n",
    "\n",
    "#create a dictionary orders -> itemID -> podID\n",
    "#This dictionary is for dedicated policy, for mix policy for each itemID will be list of podID\n",
    "def get_order_itemID_podID(orders = orders_list):\n",
    "  order_itemID_item_color_letter = get_order_itemID_letter_color(orders)\n",
    "  podID_pod_letter_color = get_podID_pod_letter_color()\n",
    "  order_itemID_podID = {}\n",
    "  for order in orders:\n",
    "    order_itemID_podID[order] = {}\n",
    "    for itemID, letter_color in order_itemID_item_color_letter[order].items():\n",
    "        for podID, list_letter_color in podID_pod_letter_color.items():\n",
    "          if letter_color in list_letter_color:\n",
    "            order_itemID_podID[order][itemID] = podID\n",
    "  return order_itemID_podID\n",
    "\n",
    "\n",
    "#for dedicated policy we need just dictionary: order -> podID:          \n",
    "def get_order_podID(orders = orders_list):\n",
    "  order_itemID_item_color_letter = get_order_itemID_letter_color(orders)\n",
    "  podID_pod_letter_color = get_podID_pod_letter_color()\n",
    "  order_podID = defaultdict(list)\n",
    "  for order in orders:\n",
    "    for itemID, letter_color in order_itemID_item_color_letter[order].items():\n",
    "        for podID, list_letter_color in podID_pod_letter_color.items():\n",
    "          if letter_color in list_letter_color:\n",
    "            order_podID[order] += [podID]\n",
    "  return order_podID\n",
    "\n",
    "#Creating a function to get amount of items for particular order:\n",
    "def get_order_podID_itemcount(orders = orders_list):\n",
    "  order_itemID_podID = get_order_itemID_podID()\n",
    "  order_podID_itemcount = {}\n",
    "  for order in orders_list:\n",
    "    order_podID_itemcount[order] = {}\n",
    "    for itemID, pos in order.Positions.items():\n",
    "      podID = order_itemID_podID[order][itemID]\n",
    "      order_podID_itemcount[order][podID] = float(pos.Count)\n",
    "  return order_podID_itemcount\n",
    "\n",
    "#create a dictionary podID -> itemID\n",
    "#This dictionary is for dedicated policy, for mix policy for each podID will be list of itemID\n",
    "def get_podID_itemID(orders = orders_list):\n",
    "  order_itemID_item_color_letter = get_order_itemID_letter_color(orders_list)\n",
    "  podID_pod_letter_color = get_podID_pod_letter_color()\n",
    "  podID_itemID = {}\n",
    "  for order in orders:\n",
    "    for itemID, letter_color in order_itemID_item_color_letter[order].items():\n",
    "      for podID, list_letter_color in podID_pod_letter_color.items():\n",
    "        if letter_color in list_letter_color:\n",
    "          podID_itemID[podID] = itemID\n",
    "  return podID_itemID\n",
    "\n",
    "#To get the weights of the orders\n",
    "def get_order_weights(orders = orders_list):\n",
    "  order_weights = {}\n",
    "  for order in orders:\n",
    "    order_weights[order] = extract_order_weight(order, ItemDescriptions = _demo.warehouseInstance.ItemDescriptions)\n",
    "  return order_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV3kIjZyZ2cz"
   },
   "source": [
    "## Assigning orders to the packing stations (depots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "2mbJUVBb4Uzi"
   },
   "outputs": [],
   "source": [
    "def orders_to_depots_recursive(orders_, depot_to_order_distances, depot_assignment_dict,\n",
    "                               orders_str, orders_match, orders_match_rev, w_i, w_o, c, B_star, depots):\n",
    "    #creating list of mu:\n",
    "    while orders_ != []:\n",
    "      mu_list = []\n",
    "      priority_list = []\n",
    "      for order in orders_:\n",
    "          d = list(depot_to_order_distances[order].values()) # list of distances from order to depots\n",
    "          depots_list = list(depot_to_order_distances[order].keys())\n",
    "          lists_to_sort = zip(d, depots_list)\n",
    "          sorted_lists_d = sorted(lists_to_sort)  # sorted according to d\n",
    "          d_sorted = [elem for elem,_ in sorted_lists_d]\n",
    "          depots_list_sorted = [elem for _,elem in sorted_lists_d]\n",
    "          priority = depots_list_sorted[0]\n",
    "          #getting priority for assignment before balancing:\n",
    "          if len(d) > 1:\n",
    "              mu = d_sorted[1] - d_sorted[0] #difference in distances from order to depots between shortest and second shortest\n",
    "              mu_list.append(mu)\n",
    "              priority_list.append(priority)\n",
    "          #if there is only one choice of depot then assign order to it:\n",
    "          elif len(d) == 1:\n",
    "              depot_assignment_dict[priority][order] = 1  # assigning the order to depot\n",
    "              w_i[priority] = w_i[priority] + w_o[order] #adding the weight to the depot\n",
    "              orders_str.remove(orders_match_rev[order])\n",
    "              orders_.remove(order)\n",
    "      #sort orders according to mu\n",
    "      lists_to_sort = zip(mu_list, orders_str, priority_list)\n",
    "      sorted_lists = sorted(lists_to_sort, reverse=True )#sorted according to mu in discending order\n",
    "      orders_str_sorted = [elem for _1, elem, _3 in sorted_lists]\n",
    "      orders_sorted = []\n",
    "      for order_str in orders_str_sorted:\n",
    "        orders_sorted.append(orders_match[order_str])\n",
    "      priority_list_sorted = [elem for _1, _2, elem in sorted_lists]\n",
    "      for index, order in enumerate(orders_sorted):\n",
    "          if orders_ == [] or len(list(depot_to_order_distances[order].values())) == 1:\n",
    "            break\n",
    "          depot_ = priority_list_sorted[index]\n",
    "          if (w_i[depot_] + w_o[order]) / c <= B_star / len(depots):\n",
    "              depot_assignment_dict[depot_][order] = 1 #assigning the order to depot\n",
    "              w_i[depot_] = w_i[depot_] + w_o[order]\n",
    "              orders_str.remove(orders_match_rev[order])\n",
    "              orders_.remove(order)\n",
    "          else:\n",
    "              depot_to_order_distances[order].pop(depot_)\n",
    "            #orders_to_depots_recursive(orders_, depot_to_order_distances, depot_assignment_dict,\n",
    "            #                                     orders_str, orders_match, orders_match_rev, w_i, w_o, c, B_star, depots)\n",
    "\n",
    "\n",
    "#Assigning orders to depots \n",
    "def assigning_orders_to_depots(depots = _demo.warehouseInstance.OutputStations.keys(), \n",
    "                               podID_list = _demo.warehouseInstance.Pods.keys(), \n",
    "                               orders_list = orders_list, distances = _demo.distance_ij, c = 18):\n",
    "  orders_ = orders_list.copy()\n",
    "  order_podID = get_order_podID(orders_)\n",
    "  order_weights = get_order_weights(orders_)\n",
    "  orders_str = ['OC'+ str(i+1) for i in range(len(orders_))] #we need this list to sort orders\n",
    "  orders_match = dict(zip(orders_str, orders_)) #we need this dictionary to get correspondent order for order_str after sorting\n",
    "  orders_match_rev = dict(zip(orders_,orders_str)) #reversed dictionary to delete orders from both lists after assignment\n",
    "  #set of distances from depot to order:\n",
    "  depot_to_order_distances = {}\n",
    "  for order in orders_:\n",
    "    depot_to_order_distances[order] = {}\n",
    "    for depot in depots:\n",
    "      tmp = 0\n",
    "      for podID in order_podID[order]:\n",
    "        tmp += distances[(depot, podID)]\n",
    "      depot_to_order_distances[order][depot] = tmp\n",
    "  w_o = order_weights #weights of the orders\n",
    "  cum_orders_weight = sum([w_o[order] for order in orders_]) #total weight of the orders\n",
    "  #min number of batches to get all orders\n",
    "  B_star = math.ceil(cum_orders_weight / c)\n",
    "  # Initialization\n",
    "  depot_assignment_dict = {\n",
    "      depot: dict(zip(orders_, [0 for i in range(len(orders_))]))\n",
    "      for depot in depots}  # set all orders not assigned\n",
    "  weight_stations = [sum([depot_assignment_dict[depot][order] * w_o[order] for order in orders_]) for depot in depots]\n",
    "  w_i = dict(zip(depots, weight_stations))  # weights of the stations\n",
    "  ###\n",
    "  #Recursive function to assign orders to depots\n",
    "  orders_to_depots_recursive(orders_, depot_to_order_distances, \n",
    "                            depot_assignment_dict, orders_str, orders_match, \n",
    "                            orders_match_rev, w_i, w_o, c, B_star, depots)\n",
    "  ###\n",
    "  #Changing the format to more convenient one\n",
    "  depot_order_assignmnet = defaultdict(list)\n",
    "  for depot, order_value in depot_assignment_dict.items():\n",
    "    for order, value in order_value.items():\n",
    "      if value == 1:\n",
    "        depot_order_assignmnet[depot] += [order]\n",
    "  return depot_order_assignmnet , orders_match_rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUxgFLC1P7Bd",
    "outputId": "ef4ddf37-c4d2-4b3e-bf21-b9da81cdc366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'OutD0': [<rafs_instance.Order at 0x7f95f0cf3610>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1850>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1450>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf0ad0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf0d90>,\n",
       "              <rafs_instance.Order at 0x7f95f0cec9d0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cecd90>,\n",
       "              <rafs_instance.Order at 0x7f95f0d5d1d0>],\n",
       "             'OutD1': [<rafs_instance.Order at 0x7f95f0cf3690>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf3590>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1dd0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1c50>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1d10>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1ad0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf1950>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf03d0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cf02d0>,\n",
       "              <rafs_instance.Order at 0x7f95f0cec150>,\n",
       "              <rafs_instance.Order at 0x7f95f0cecb10>,\n",
       "              <rafs_instance.Order at 0x7f95f0cecad0>]})"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depot_order_assignmnet, orders_match_ID = assigning_orders_to_depots(orders_list = orders_list)\n",
    "depot_order_assignmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoooNitqaDUb"
   },
   "source": [
    "## Assigning orders to batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "dGsGKjw80FDL"
   },
   "outputs": [],
   "source": [
    "#The function to get dictionary of the batch weights\n",
    "def get_depot_batch_weight():\n",
    "  batches_of_depots = get_batches_of_depots()\n",
    "  depot_batch_weight = {}\n",
    "  order_weights = get_order_weights()\n",
    "  for depot in batches_of_depots.keys():\n",
    "    depot_batch_weight[depot] = {}\n",
    "    for batchnr, batch in batches_of_depots[depot].items():\n",
    "      weight = 0\n",
    "      for order in batch:\n",
    "        weight += order_weights[order]\n",
    "      depot_batch_weight[depot][batchnr] =  weight\n",
    "  return depot_batch_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "Ds6-fHMu9hrC"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary with all distances between orders calculated\n",
    "def distance_matrix(O_i, distances = _demo.distance_ij):\n",
    "  order_podID = get_order_podID()\n",
    "  distances_between_orders = {}\n",
    "  for order_1 in O_i:\n",
    "    distances_between_orders[order_1] = {}\n",
    "    for order_2 in O_i:\n",
    "      distance_orders = 0\n",
    "      for podID_1 in order_podID[order_1]:\n",
    "        distance_items = 0\n",
    "        for podID_2 in order_podID[order_2]:\n",
    "          distance_items += distances[(podID_1,podID_2)]       \n",
    "        distance_orders += distance_items\n",
    "      distances_between_orders[order_1][order_2] = distance_orders\n",
    "  return distances_between_orders\n",
    "\n",
    "#The function to find the closest orders from the batch\n",
    "def new_order_of_batch(O_i, O_temp, distances_between_orders):\n",
    "  if O_temp == []:\n",
    "    o_batch_new = random.choice(O_i)\n",
    "  all_distances_list = []\n",
    "  # loop through orders unassigned to a batch in this depot\n",
    "  for candidate_order in O_i:\n",
    "    distance_candidate = 0\n",
    "    # loop through the orders already assigned to this batch in this depot\n",
    "    for order_temp in O_temp:\n",
    "      distance_candidate += distances_between_orders[candidate_order][order_temp]\n",
    "    all_distances_list.append(distance_candidate)\n",
    "  min_distance = min(all_distances_list) \n",
    "  min_distance_ind = all_distances_list.index(min_distance) \n",
    "  o_batch_new = O_i[min_distance_ind]\n",
    "  return o_batch_new\n",
    "\n",
    "#Function to assign orders from one depot to batches:\n",
    "def assigning_orders_to_batches(depot):\n",
    "  batchnr = 1\n",
    "  batches_of_orders = {}\n",
    "  packing_station_orders, _ = assigning_orders_to_depots()\n",
    "  O_i = packing_station_orders[depot]\n",
    "  order_weights = get_order_weights(O_i)\n",
    "  distances_between_orders = distance_matrix(O_i, distances = _demo.distance_ij)\n",
    "  c = 18 \n",
    "  for order in O_i:\n",
    "    if order_weights[order] > c:#we found out that in 20_5a and 20_5b there are orders heavier than 18\n",
    "    #print(o_batch_new)\n",
    "      O_i.remove(order) #make sure we do not allow orders heavier than batch capacity\n",
    "  while O_i != []: #iterate till all orders of the station are assigned\n",
    "    weight = 0\n",
    "    O_temp = []#list of orders in the batch\n",
    "    i = 0 \n",
    "    while any(weight + order_weights[o] <= c for o in O_i): #control weight capacity of the batch\n",
    "    #find minimum distance order for the batch:\n",
    "      o_batch_new = new_order_of_batch(O_i, O_temp, distances_between_orders)\n",
    "      if weight + order_weights[o_batch_new] <= c:\n",
    "        o_batch_new = o_batch_new\n",
    "      else:\n",
    "        for order in O_i:#searching for other orders to fit in the batch\n",
    "          if weight + order_weights[order] <= c:\n",
    "            O_i_add = O_i.copy()\n",
    "            O_i_add.remove(o_batch_new)\n",
    "            o_batch_new = new_order_of_batch(O_i_add, O_temp, distances_between_orders)\n",
    "      weight += order_weights[o_batch_new]\n",
    "      O_temp.append(o_batch_new)\n",
    "      O_i.remove(o_batch_new)        \n",
    "    batches_of_orders[batchnr] = O_temp\n",
    "    batchnr += 1\n",
    "  return batches_of_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "8iO5NfBRMgpn"
   },
   "outputs": [],
   "source": [
    "#getting the assignment of all orders to batches:\n",
    "def get_batches_of_depots(packing_stations = packing_stations):\n",
    "  batches_of_depots = {}\n",
    "  for depot in packing_stations:\n",
    "    batches_of_depots[depot] = defaultdict(list)\n",
    "    batches_of_depots[depot] = assigning_orders_to_batches(depot)\n",
    "  return batches_of_depots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMZ9pjf_BzDN",
    "outputId": "12494cfc-e64a-4ca6-8668-41fe2dc80653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OutD0': {1: [<rafs_instance.Order at 0x7f95f0cf3610>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf1450>],\n",
       "  2: [<rafs_instance.Order at 0x7f95f0cf1850>,\n",
       "   <rafs_instance.Order at 0x7f95f0cecd90>],\n",
       "  3: [<rafs_instance.Order at 0x7f95f0cf0ad0>],\n",
       "  4: [<rafs_instance.Order at 0x7f95f0cf0d90>],\n",
       "  5: [<rafs_instance.Order at 0x7f95f0cec9d0>,\n",
       "   <rafs_instance.Order at 0x7f95f0d5d1d0>]},\n",
       " 'OutD1': {1: [<rafs_instance.Order at 0x7f95f0cf3690>,\n",
       "   <rafs_instance.Order at 0x7f95f0cec150>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf02d0>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf1950>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf1c50>],\n",
       "  2: [<rafs_instance.Order at 0x7f95f0cf3590>,\n",
       "   <rafs_instance.Order at 0x7f95f0cecb10>],\n",
       "  3: [<rafs_instance.Order at 0x7f95f0cf1dd0>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf03d0>,\n",
       "   <rafs_instance.Order at 0x7f95f0cf1ad0>],\n",
       "  4: [<rafs_instance.Order at 0x7f95f0cf1d10>,\n",
       "   <rafs_instance.Order at 0x7f95f0cecad0>]}}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_of_depots = get_batches_of_depots()\n",
    "batches_of_depots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tfbIPWy3yCR",
    "outputId": "8a6a811f-a8aa-464c-f132-113a52eaaa2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OutD0': {1: 17.52, 2: 13.55, 3: 17.79, 4: 13.870000000000001, 5: 17.57},\n",
       " 'OutD1': {1: 15.3, 2: 17.529999999999998, 3: 16.41, 4: 15.19}}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depot_batch_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT5MeQIuaLRv"
   },
   "source": [
    "## Searching for the best routes for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "yQgDJ6_PxN1v"
   },
   "outputs": [],
   "source": [
    "# searching for the best route of the batches\n",
    "def find_best_route(batch, depot):\n",
    "    # batch is the list of orders\n",
    "    remaining = []  # the list of the podID for all items in the batch\n",
    "    order_podID = get_order_podID()\n",
    "    for order in batch:\n",
    "        for podID in order_podID[order]:\n",
    "            if not podID in remaining:\n",
    "                remaining.append(podID)\n",
    "    start = depot  # the start and end point is packing station\n",
    "    head = depot  # the starting point is the depot\n",
    "    path = [head]  # keep track of the locations visited\n",
    "    distance = 0.0\n",
    "    while len(remaining) > 0:  # loop until all locations are visited in the order\n",
    "        ds = {}\n",
    "        #print(remaining)\n",
    "        for position in remaining:\n",
    "            ds[position] = distances[(head, position)]\n",
    "        best, best_distance = sorted(ds.items(), key=lambda x: x[1])[0]  # select shortest path\n",
    "        remaining.remove(best)  # remove the location from the not visited dict.\n",
    "        head = best  # update the head of the path to the current location of the cobot\n",
    "        path += [best]  # update the path taken by the cobot\n",
    "        distance += best_distance  # update the distance traveled by the cobot\n",
    "    distance += distances[(head, start)]  # add the distance for going back to the packing station\n",
    "    path += [start]  # adding the packing station to the path\n",
    "    return path, distance\n",
    "\n",
    "\n",
    "# find init solution:\n",
    "def initial_solution(packing_stations = packing_stations):\n",
    "  batches_of_depots = get_batches_of_depots(packing_stations)\n",
    "  depot_batch_bestpath = {}\n",
    "  depot_batch_bestdistance = {}\n",
    "  for depot in packing_stations:\n",
    "      depot_batch_bestpath[depot] = {}\n",
    "      depot_batch_bestdistance[depot] = {}\n",
    "      for batchnr, batch in batches_of_depots[depot].items():\n",
    "          bestpath, bestdistance = find_best_route(batch, depot)\n",
    "          depot_batch_bestpath[depot][batchnr] = bestpath\n",
    "          depot_batch_bestdistance[depot][batchnr] = bestdistance\n",
    "  sum_of_batch_distances = [sum(depot_batch_bestdistance[depot].values()) for depot in packing_stations]\n",
    "  return depot_batch_bestpath, sum_of_batch_distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gyb3JUpPm3pd",
    "outputId": "39cd1c3b-74c2-4a67-c272-0dec29c58f4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'OutD0': {1: ['OutD0',\n",
       "    '150',\n",
       "    '129',\n",
       "    '172',\n",
       "    '14',\n",
       "    '36',\n",
       "    '35',\n",
       "    '47',\n",
       "    '51',\n",
       "    '23',\n",
       "    '215',\n",
       "    'OutD0'],\n",
       "   2: ['OutD0', '150', '128', '74', '79', '14', '35', '215', '217', 'OutD0'],\n",
       "   3: ['OutD0',\n",
       "    '150',\n",
       "    '215',\n",
       "    '74',\n",
       "    '67',\n",
       "    '79',\n",
       "    '14',\n",
       "    '35',\n",
       "    '23',\n",
       "    '266',\n",
       "    'OutD0'],\n",
       "   4: ['OutD0', '150', '128', '172', '217', '215', '67', '51', '36', 'OutD0'],\n",
       "   5: ['OutD0',\n",
       "    '150',\n",
       "    '128',\n",
       "    '74',\n",
       "    '67',\n",
       "    '14',\n",
       "    '36',\n",
       "    '35',\n",
       "    '51',\n",
       "    '23',\n",
       "    '215',\n",
       "    '349',\n",
       "    'OutD0']},\n",
       "  'OutD1': {1: ['OutD1',\n",
       "    '23',\n",
       "    '51',\n",
       "    '47',\n",
       "    '14',\n",
       "    '74',\n",
       "    '67',\n",
       "    '150',\n",
       "    '217',\n",
       "    'OutD1'],\n",
       "   2: ['OutD1',\n",
       "    '144',\n",
       "    '172',\n",
       "    '128',\n",
       "    '150',\n",
       "    '35',\n",
       "    '36',\n",
       "    '47',\n",
       "    '51',\n",
       "    '28',\n",
       "    '266',\n",
       "    'OutD1'],\n",
       "   3: ['OutD1', '266', '349', '129', '150', '67', '14', '35', '47', 'OutD1'],\n",
       "   4: ['OutD1',\n",
       "    '172',\n",
       "    '128',\n",
       "    '150',\n",
       "    '35',\n",
       "    '14',\n",
       "    '47',\n",
       "    '51',\n",
       "    '23',\n",
       "    '28',\n",
       "    '266',\n",
       "    'OutD1']}},\n",
       " [830.8999999999997, 592.5999999999997])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtKrhi6_yhAk"
   },
   "source": [
    "## Makespan algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulWzx-xaqPg8"
   },
   "source": [
    "### Assigning pods to zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "2t2QyEPIqU60"
   },
   "outputs": [],
   "source": [
    "pods_dict = _demo.warehouseInstance.Pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "W3RMRyt4Q8mn"
   },
   "outputs": [],
   "source": [
    "#We need a function to make our solution without batchnumbers, as one path:\n",
    "def flatten_batches(depot_batch_bestpath):\n",
    "  cobot_path = defaultdict(list)\n",
    "  for cobot in depot_batch_bestpath.keys():\n",
    "    for batch in depot_batch_bestpath[cobot].values():\n",
    "      for podID in batch:\n",
    "        if cobot_path[cobot] != [] and cobot_path[cobot][-1] == podID:\n",
    "          continue\n",
    "        cobot_path[cobot].append(podID)\n",
    "  return cobot_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "CQwALA8plUVv"
   },
   "outputs": [],
   "source": [
    "#Creating neccessary data structures:\n",
    "#creating a list of zones:\n",
    "def get_zones(pods_dict = pods_dict):\n",
    "  if len(list(pods_dict.keys())) == 24:\n",
    "    zones = ['zone_'+ str(i+1) for i in range(2)]\n",
    "  else:\n",
    "    zones = ['zone_'+ str(i+1) for i in range(6)]\n",
    "  return zones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "hFrjP_szrf2-"
   },
   "outputs": [],
   "source": [
    "#dictionary PodID -> zone:\n",
    "def get_podID_zone(pods_dict = pods_dict):\n",
    "  zones = get_zones(pods_dict)\n",
    "  podID_list = list(pods_dict.keys())\n",
    "  podID_zone = {}\n",
    "  for ind, zone in enumerate(zones):\n",
    "    num_zone = ind + 1\n",
    "    start_element = int((num_zone - 1)*len(podID_list)/len(zones))\n",
    "    end_element = int(num_zone*len(podID_list)/len(zones))\n",
    "    for podID in podID_list[start_element:end_element]:\n",
    "      podID_zone[podID] = zone  \n",
    "  return podID_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "eFDEz0wrR3U0"
   },
   "outputs": [],
   "source": [
    "  #dictionary that contains instead of items their corresponding zones, represented as one path (without batches):\n",
    "  def get_cobot_item_zones(solution):\n",
    "    podID_zone = get_podID_zone()\n",
    "    cobot_item_zones = defaultdict(list)\n",
    "    for depot in solution.keys():\n",
    "      for batchnr, batch in solution[depot].items():\n",
    "        cobot_item_zones[depot].append(depot)\n",
    "        for podID in batch[1:-1]:   \n",
    "          cobot_item_zones[depot].append(podID_zone[podID])\n",
    "      cobot_item_zones[depot].append(depot)  \n",
    "    return cobot_item_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "aGrJvwghaaFA"
   },
   "outputs": [],
   "source": [
    "def get_cobot_zone_sequence(solution):\n",
    "    podID_zone = get_podID_zone()\n",
    "    cobot_zone_sequence = defaultdict(list)\n",
    "    for depot in solution.keys():\n",
    "      for batchnr, batch in solution[depot].items():\n",
    "        for podID in batch[1:-1]:  \n",
    "          cobot_zone_sequence[depot].append(podID_zone[podID]) \n",
    "        cobot_zone_sequence[depot].append(depot)\n",
    "      cobot_zone_sequence[depot] = [i[0] for i in groupby(cobot_zone_sequence[depot])]\n",
    "    return cobot_zone_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDidatgLqZRg"
   },
   "source": [
    "###  Dictionary to collect right amount of items from shelfs on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "wHTuW4BD8qsX"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary to get amount of item to pick grom each pod:\n",
    "def get_depot_batch_podID_itemcount(solution_orders, packing_stations = packing_stations, orders = orders_list):\n",
    "  order_podID_itemcount = get_order_podID_itemcount(orders)\n",
    "  depot_batch_podID_itemcount = {}  \n",
    "  for depot in batches_of_depots.keys():\n",
    "    depot_batch_podID_itemcount[depot] = {}\n",
    "    for batchnr, orders_of_batch in solution_orders[depot].items():\n",
    "      depot_batch_podID_itemcount[depot][batchnr] = {}\n",
    "      for order in orders_of_batch:\n",
    "        for podID, itemcount in order_podID_itemcount[order].items():\n",
    "          if podID in depot_batch_podID_itemcount[depot][batchnr].keys():\n",
    "            depot_batch_podID_itemcount[depot][batchnr][podID] += itemcount\n",
    "          else:\n",
    "            depot_batch_podID_itemcount[depot][batchnr][podID] = itemcount\n",
    "  return depot_batch_podID_itemcount\n",
    "\n",
    "\n",
    "#For our purposes we need flat version of the dictionary above:\n",
    "def get_depot_itemcount(solution, solution_orders):\n",
    "  depot_batch_podID_itemcount = get_depot_batch_podID_itemcount(solution_orders)\n",
    "  depot_itemcount = defaultdict(list)\n",
    "  for depot in depot_batch_podID_itemcount.keys():\n",
    "    for batchnr in depot_batch_podID_itemcount[depot].keys():\n",
    "      for podID in solution[depot][batchnr]:\n",
    "        if podID == depot:\n",
    "          continue\n",
    "        else: depot_itemcount[depot].append(depot_batch_podID_itemcount[depot][batchnr][podID])\n",
    "  return depot_itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgUo6fC7ak85"
   },
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "FmRDhjiyMiy0"
   },
   "outputs": [],
   "source": [
    "#we need function to calculate serving time of a cobot in a zone:\n",
    "def picker_serving(zone, cobot, cobot_paths, cobot_item_zones, picker_speed, picking_time, distances, depot_itemcount):\n",
    "  t_picking = picking_time*depot_itemcount[cobot][0]\n",
    "  t_serving = t_picking\n",
    "  del depot_itemcount[cobot][0]\n",
    "  while cobot_item_zones[cobot][1] == zone:\n",
    "    t_picker_travel = distances[(cobot_paths[cobot][0],cobot_paths[cobot][1])]/picker_speed\n",
    "    t_picking = picking_time*depot_itemcount[cobot][0]\n",
    "    t_serving = t_serving + t_picker_travel + t_picking\n",
    "    del cobot_item_zones[cobot][0]\n",
    "    del depot_itemcount[cobot][0]\n",
    "    del cobot_paths[cobot][0]\n",
    "  last_pod = cobot_paths[cobot][0]\n",
    "  return last_pod, t_serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "S40lUDTAqGA6"
   },
   "outputs": [],
   "source": [
    "#function that to calculate the time of cobot spent in the zone on serving\n",
    "def zone_time(t_start, zone, cobot, cobot_paths, cobot_item_zones, cobot_zone_sequence, picker_speed, picking_time, distances, depot_itemcount, zones_occupation_time):\n",
    "  #deleting previous waypoints:\n",
    "  del cobot_item_zones[cobot][0]\n",
    "  del cobot_paths[cobot][0]\n",
    "  #calculating serving time (picking time for all items of the zone):\n",
    "  last_pod, t_serving = picker_serving(zone, cobot, cobot_paths, cobot_item_zones, \n",
    "                                       picker_speed, picking_time, distances, depot_itemcount)\n",
    "  #calculating finishing time for the zone\n",
    "  t_finish = t_start + t_serving\n",
    "  zones_occupation_time[zone] = (t_start, t_finish)\n",
    "  #updating times and position of the cobot\n",
    "  del cobot_zone_sequence[cobot][0]\n",
    "  return t_finish, last_pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "4dUA47ELrxT7"
   },
   "outputs": [],
   "source": [
    "#the function for calculating the makespan \n",
    "def get_makespan(solution, solution_orders):\n",
    "  solution_ = solution.copy()\n",
    "  zones = get_zones(pods_dict)\n",
    "  ###\n",
    "  zones_occupation_time = {}\n",
    "  t_start = 0\n",
    "  t_finish = 0\n",
    "  for zone in zones:\n",
    "    zones_occupation_time[zone] = (t_start, t_finish)\n",
    "  zones_occupation_time\n",
    "  ###\n",
    "  picker_position = {}\n",
    "  for zone in zones:\n",
    "    picker_position[zone] = 0\n",
    "  ###\n",
    "  depot_occupation_time = {}\n",
    "  t_pack_start = 0\n",
    "  t_pack_finish = 0\n",
    "  for depot in packing_stations:\n",
    "    depot_occupation_time[depot] = (t_pack_start, t_pack_finish)\n",
    "  #parameters:\n",
    "  cobot_speed = 2\n",
    "  picker_speed = 1.3\n",
    "  picking_time = 3 \n",
    "  t_prep = 30 \n",
    "  t_unload = 20 \n",
    "  t_packing = 60 \n",
    "  cobots = packing_stations.copy()#to be able to delete cobots that finished their jobs\n",
    "  ###\n",
    "  #neccessary data structures:\n",
    "  podID_zone = get_podID_zone()#to extract zone of the item\n",
    "  batches_of_depots = solution_orders\n",
    "  depot_batch_bestpath = solution_\n",
    "  depot_itemcount = get_depot_itemcount(depot_batch_bestpath, batches_of_depots)#to know how many items to pick\n",
    "  cobot_paths = flatten_batches(depot_batch_bestpath)#cobot path\n",
    "  cobot_zone_sequence = get_cobot_zone_sequence(depot_batch_bestpath)#to know next zone to visit\n",
    "  cobot_item_zones = get_cobot_item_zones(depot_batch_bestpath)#path with zones instead of corresponding items\n",
    "  ###\n",
    "  waiting_time = defaultdict(list)#we will append here all waiting times before each new zone for cobot\n",
    "  #creating a dictionary to set current time to time that was spent on preparation\n",
    "  t_current = {}\n",
    "  for cobot in packing_stations:\n",
    "    t_current[cobot] = t_prep\n",
    "  #The body of the algorithm:\n",
    "  while any(cobot_zone_sequence[cobot]  != [] for cobot in packing_stations):#till all zones of the path are visited (depots are also zones)\n",
    "    #determining the next zone for each cobot:\n",
    "    next_zone = []\n",
    "    for cobot in packing_stations:\n",
    "      if cobot_zone_sequence[cobot] == []:\n",
    "        if cobot in cobots:\n",
    "          cobots.remove(cobot)\n",
    "      else:\n",
    "        next_zone.append(cobot_zone_sequence[cobot][0])\n",
    "    if len(next_zone) != len(set(next_zone)):#check if cobots plan to go to the same zone\n",
    "      next_zone_ = next_zone[0]\n",
    "      t_arrival_next_zone = []\n",
    "      for cobot in packing_stations:\n",
    "        t_arrival_next_zone.append(t_current[cobot] + distances[(cobot_paths[cobot][0], cobot_paths[cobot][1])]/cobot_speed)\n",
    "      min_time = min(t_arrival_next_zone) \n",
    "      min_time_ind = t_arrival_next_zone.index(min_time) \n",
    "      cobot_first = packing_stations[min_time_ind]\n",
    "      cobot_second = packing_stations[min_time_ind-1]\n",
    "      t_travel = distances[(cobot_paths[cobot_first][0], cobot_paths[cobot_first][1])]/cobot_speed\n",
    "      #in case if picker needs more time to get to the first item than first cobot\n",
    "      if picker_position[next_zone_] != 0:#check if it is the first item for cobot\n",
    "        t_travel_picker = distances[(picker_position[next_zone_], cobot_paths[cobot_first][1])]/picker_speed\n",
    "        if t_current[cobot_first] + t_travel  < zones_occupation_time[next_zone_][1] + t_travel_picker: #if picker will arrive later than cobot can\n",
    "          t_start = zones_occupation_time[next_zone_][1] + t_travel_picker\n",
    "          waiting_time[cobot_first].append(zones_occupation_time[next_zone_][1] + t_travel_picker - t_current[cobot_first] - t_travel)\n",
    "        else:\n",
    "          t_start = t_current[cobot_first] + t_travel\n",
    "      else:  \n",
    "        t_start = t_current[cobot_first] + t_travel  \n",
    "      t_finish, picker_position[next_zone_] = zone_time(t_start, next_zone_, cobot_first, cobot_paths, cobot_item_zones,\n",
    "                                         cobot_zone_sequence, picker_speed, picking_time, distances, depot_itemcount, zones_occupation_time)\n",
    "      t_current[cobot_first] = t_finish\n",
    "      ###Calculating waiting time of the second cobot:\n",
    "      t_travel = distances[(cobot_paths[cobot_second][0], cobot_paths[cobot_second][1])]/cobot_speed\n",
    "      t_travel_picker = distances[(picker_position[next_zone_], cobot_paths[cobot_second][1])]/picker_speed\n",
    "      if t_current[cobot_second] + t_travel  <= t_finish + t_travel_picker: \n",
    "        waiting_time[cobot_second].append(t_finish + t_travel_picker - t_travel - t_current[cobot_second])\n",
    "        t_current[cobot_second] =  t_current[cobot_second] + waiting_time[cobot_second][-1]\n",
    "      t_start = t_current[cobot_second] + t_travel\n",
    "      t_current[cobot_second], picker_position[next_zone_] = zone_time(t_start, next_zone_, cobot_second, cobot_paths, \n",
    "                                         cobot_item_zones, cobot_zone_sequence, picker_speed, picking_time, distances, depot_itemcount, zones_occupation_time)\n",
    "    else:\n",
    "      for ind, cobot in enumerate(cobots):\n",
    "          t_travel = distances[(cobot_paths[cobot][0], cobot_paths[cobot][1])]/cobot_speed\n",
    "          if next_zone[ind] == cobot: #check if the next zone is depot\n",
    "            if t_current[cobot] + t_travel >= depot_occupation_time[cobot][1]: #if cobot comes when packer finished packing\n",
    "              del cobot_item_zones[cobot][0]\n",
    "              del cobot_paths[cobot][0]\n",
    "              if len(cobot_zone_sequence[cobot]) == 1: #if it is the end of the last tour of the cobot\n",
    "                t_pack_start = t_current[cobot] + t_travel + t_unload #we do not have preparation\n",
    "                t_current[cobot] = t_current[cobot] + t_travel + t_unload \n",
    "              else:\n",
    "                t_pack_start = t_current[cobot] + t_travel + t_prep + t_unload\n",
    "                t_current[cobot] = t_current[cobot] + t_travel + t_prep + t_prep + t_unload\n",
    "              t_pack_finish = t_pack_start + t_packing\n",
    "              depot_occupation_time[cobot] = (t_pack_start, t_pack_finish)\n",
    "              del cobot_zone_sequence[cobot][0]\n",
    "            else: #if packer still packing, cobot needs to wait\n",
    "              t_pack_finish = depot_occupation_time[cobot][1]\n",
    "              del cobot_item_zones[cobot][0]\n",
    "              del cobot_paths[cobot][0]\n",
    "              waiting_time[cobot].append(t_pack_finish - t_travel - t_current[cobot]) \n",
    "              t_current[cobot] += waiting_time[cobot][-1]\n",
    "              if len(cobot_zone_sequence[cobot]) == 1:#if it is the end of the last tour of the cobot\n",
    "                t_pack_start = t_current[cobot] + t_travel + t_unload\n",
    "                t_current[cobot] = t_current[cobot]   + t_travel + t_unload\n",
    "              else:\n",
    "                t_pack_start = t_current[cobot] + t_travel + t_prep + t_unload\n",
    "                t_current[cobot] = t_current[cobot] + t_travel + t_unload + t_prep\n",
    "              t_pack_finish = t_pack_start + t_packing\n",
    "              depot_occupation_time[cobot] = (t_pack_start, t_pack_finish)\n",
    "              del cobot_zone_sequence[cobot][0]\n",
    "          else:\n",
    "            if picker_position[next_zone[ind]] != 0:\n",
    "              t_travel_picker = distances[(picker_position[next_zone[ind]], cobot_paths[cobot][1])]/picker_speed\n",
    "              if t_current[cobot] + t_travel  <= zones_occupation_time[next_zone[ind]][1] + t_travel_picker: #if picker will arrive later than cobot can\n",
    "                t_start = zones_occupation_time[next_zone[ind]][1] + t_travel_picker\n",
    "                waiting_time[cobot].append(zones_occupation_time[next_zone[ind]][1] + t_travel_picker - t_current[cobot] - t_travel)\n",
    "              else:\n",
    "                t_start = t_current[cobot] + t_travel\n",
    "            else:  \n",
    "              t_start = t_current[cobot] + t_travel\n",
    "            t_current[cobot], picker_position[next_zone[ind]] = zone_time(t_start, next_zone[ind], cobot, cobot_paths, \n",
    "                                         cobot_item_zones, cobot_zone_sequence, picker_speed, picking_time, distances, depot_itemcount, zones_occupation_time)\n",
    "  total_waiting_time = sum([sum(waiting_time[depot]) for depot in packing_stations])\n",
    "  return t_pack_finish, total_waiting_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrUfl732kB2g"
   },
   "source": [
    "## Greedy Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yg04j4mBeFiL",
    "outputId": "bf01be07-e1d6-41d3-d8f7-6876e74cdc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------ Greedy RESULTS -------------------------+\n",
      "\n",
      "  initial solution: {'OutD0': {1: ['OutD0', '150', '129', '172', '14', '36', '35', '47', '51', '23', '215', 'OutD0'], 2: ['OutD0', '150', '128', '74', '79', '14', '35', '215', '217', 'OutD0'], 3: ['OutD0', '150', '215', '74', '67', '79', '14', '35', '23', '266', 'OutD0'], 4: ['OutD0', '150', '128', '172', '217', '215', '67', '51', '36', 'OutD0'], 5: ['OutD0', '150', '128', '74', '67', '14', '36', '35', '51', '23', '215', '349', 'OutD0']}, 'OutD1': {1: ['OutD1', '23', '51', '47', '14', '74', '67', '150', '217', 'OutD1'], 2: ['OutD1', '144', '172', '128', '150', '35', '36', '47', '51', '28', '266', 'OutD1'], 3: ['OutD1', '266', '349', '129', '150', '67', '14', '35', '47', 'OutD1'], 4: ['OutD1', '172', '128', '150', '35', '14', '47', '51', '23', '28', '266', 'OutD1']}}\n",
      "\n",
      "  initial solution waiting time : 93.06923076923063\n",
      "\n",
      "  initial solution makespan: 1115.761538461538\n",
      "\n",
      "+-------------------------- END ---------------------------+\n"
     ]
    }
   ],
   "source": [
    "init_solution,_ = initial_solution()\n",
    "init_solution_orders = get_batches_of_depots()\n",
    "init_solution_makespan, init_solution_waiting_time= get_makespan(init_solution, init_solution_orders )\n",
    "print('+------------------------ Greedy RESULTS -------------------------+\\n')\n",
    "print(f'  initial solution: {init_solution}\\n')\n",
    "print(f'  initial solution waiting time : {init_solution_waiting_time}\\n')\n",
    "print(f'  initial solution makespan: {init_solution_makespan}\\n')\n",
    "\n",
    "print('+-------------------------- END ---------------------------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "G52ncZhJ3b8j"
   },
   "outputs": [],
   "source": [
    "# to swap positions of two items in a batch:\n",
    "def swapPositions(list, pos1, pos2):\n",
    "  list_copy = list.copy()\n",
    "  list_copy[pos1], list_copy[pos2] = list_copy[pos2], list_copy[pos1]\n",
    "  return list_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "qsenA-ZPnD11"
   },
   "outputs": [],
   "source": [
    "# trying to find a neighbor for shuffling the orders between batches and items inside the orders:\n",
    "def find_neigbour_solution_batches(solution):\n",
    "  # initialize all the needed data:\n",
    "  order_weights = get_order_weights()\n",
    "  batches_of_depots = get_batches_of_depots(packing_stations)\n",
    "  batches_in_solution = batches_of_depots.copy()\n",
    "  solution_0 = solution.copy()\n",
    "  neighbor_solution = {}\n",
    "  solution_order_list_station1 = []\n",
    "  solution_order_list = []\n",
    "  depot_batch_bestpath = {}\n",
    "  depot_batch_bestdistance = {}\n",
    "  # get a list of the orders for each station:\n",
    "  for station, batch_number_orders in batches_in_solution.items():\n",
    "    if station == 'OutD0':\n",
    "      for num, orders_list in batch_number_orders.items():\n",
    "        if len(orders_list) > 1:\n",
    "          for i in range(len(orders_list)):\n",
    "           solution_order_list.append(orders_list[i])\n",
    "        else:\n",
    "          solution_order_list.append(orders_list[0])\n",
    "      # start the update of the batch assignment(here we do it randomly)\n",
    "      batchnr = 1\n",
    "      new_batches = dict([])\n",
    "      O_i = solution_order_list.copy()\n",
    "      random.shuffle(O_i) # making sure we change the order of the orders in the list\n",
    "      c = 18\n",
    "      while O_i != []: #iterate till all orders of the station are assigned\n",
    "        weight = 0\n",
    "        O_temp = []#list of orders in the batch\n",
    "        while any(weight + order_weights[o] <= c for o in O_i): #control weight capacity of the batch\n",
    "          #pdb.set_trace()\n",
    "          o_batch_new_assign = None\n",
    "          pos = random.randint(0, len(O_i)-1)\n",
    "          o_batch_new = O_i[pos]\n",
    "          if order_weights[o_batch_new] > c:#we found out that in 20_5a and 20_5b there are orders heavier than 18\n",
    "            O_i.remove(o_batch_new) #make sure we do not allow orders heavier than batch capacity\n",
    "          elif weight + order_weights[o_batch_new] <= c:\n",
    "            o_batch_new_assign = o_batch_new\n",
    "          else:\n",
    "            for order in O_i:\n",
    "              if weight + order_weights[order] <= c:\n",
    "                o_batch_new_assign = order\n",
    "          if o_batch_new_assign == None:\n",
    "              break\n",
    "          weight += order_weights[o_batch_new_assign]\n",
    "          O_temp.append(o_batch_new_assign)\n",
    "          O_i.remove(o_batch_new_assign)    \n",
    "\n",
    "        new_batches[batchnr] = O_temp\n",
    "        batchnr += 1\n",
    "      neighbor_solution[station] = new_batches\n",
    "    else: \n",
    "      # same as above but for the other station:\n",
    "      for num, orders_list in batch_number_orders.items():\n",
    "        if len(orders_list) > 1:\n",
    "          for i in range(len(orders_list)):\n",
    "            solution_order_list_station1.append(orders_list[i])\n",
    "        else:\n",
    "          solution_order_list_station1.append(orders_list[0])\n",
    "      batchnr = 1\n",
    "      new_batches = dict([])\n",
    "      O_i = solution_order_list_station1.copy()\n",
    "      random.shuffle(O_i)\n",
    "      c = 18\n",
    "      while O_i != []: #iterate till all orders of the station are assigned\n",
    "        weight = 0\n",
    "        O_temp = []#list of orders in the batch\n",
    "        while any(weight + order_weights[o] <= c for o in O_i ) and O_i != []: #control weight capacity of the batch\n",
    "          #pdb.set_trace()\n",
    "          o_batch_new_assign = None\n",
    "          pos = random.randint(0, len(O_i)-1)\n",
    "          o_batch_new = O_i[pos]\n",
    "          if order_weights[o_batch_new] > c:#we found out that in 20_5a and 20_5b there are orders heavier than 18\n",
    "            O_i.remove(o_batch_new) #make sure we do not allow orders heavier than batch capacity\n",
    "          elif weight + order_weights[o_batch_new] <= c:\n",
    "            o_batch_new_assign = o_batch_new\n",
    "          else:\n",
    "            for order in O_i:\n",
    "              if weight + order_weights[order] <= c:\n",
    "                o_batch_new_assign = order\n",
    "          if o_batch_new_assign == None:\n",
    "              break\n",
    "          weight += order_weights[o_batch_new_assign]\n",
    "          O_temp.append(o_batch_new_assign)\n",
    "          O_i.remove(o_batch_new_assign)    \n",
    "\n",
    "        new_batches[batchnr] = O_temp\n",
    "        batchnr += 1\n",
    "      neighbor_solution[station] = new_batches\n",
    "    # now we have assigned orders to batches, saved in neighbor_solution dictionary\n",
    "\n",
    "    # we will now determin the bath in greedy way for each batch\n",
    "    # but we will also switch two items positions to add some randomness\n",
    "    depot_batch_bestpath[station] = {}\n",
    "    depot_batch_bestdistance[station] = {}\n",
    "    for batchnr, batch in neighbor_solution[station].items():\n",
    "      bestpath, bestdistance = find_best_route(batch, station)\n",
    "      depot_batch_bestpath[station][batchnr] = bestpath\n",
    "      pos1 = random.randint(1,len(bestpath) - 2)\n",
    "      pos2 = random.randint(1, len(bestpath) - 2)\n",
    "      depot_batch_bestpath[station][batchnr] = swapPositions(bestpath,pos1,pos2)\n",
    "  return depot_batch_bestpath, neighbor_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "3cQdIuTBwKFE"
   },
   "outputs": [],
   "source": [
    "# finding a local neighbour solution by randomly exchanging positions of items inside batches:\n",
    "def find_neigbour_solution_local(solution):\n",
    "    solution_ = solution.copy()\n",
    "    depot_batch_bestpath = {}\n",
    "    depot_batch_bestdistance = {}\n",
    "    for station in solution_.keys():\n",
    "      depot_batch_bestpath[station] = {}\n",
    "      depot_batch_bestdistance[station] = {}\n",
    "      for batchnr, batch in solution_[station].items():\n",
    "        pos1 = random.randint(1,len(batch) - 2)\n",
    "        pos2 = random.randint(1, len(batch) - 2)\n",
    "        depot_batch_bestpath[station][batchnr] = swapPositions(batch,pos1,pos2)\n",
    "    return depot_batch_bestpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oiiwyE0rsPP"
   },
   "source": [
    "# itterated local search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmiOQ6kiEOUa",
    "outputId": "268ddcb5-066c-408c-a26f-82d74195165d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------ Local Search RESULTS -------------------------+\n",
      "\n",
      "local solution: {'OutD0': {1: ['OutD0', '150', '129', '14', '35', '36', '172', '47', '23', '51', '215', 'OutD0'], 2: ['OutD0', '128', '150', '74', '79', '14', '35', '217', '215', 'OutD0'], 3: ['OutD0', '150', '266', '23', '67', '74', '14', '35', '79', '215', 'OutD0'], 4: ['OutD0', '150', '128', '67', '51', '215', '217', '172', '36', 'OutD0'], 5: ['OutD0', '150', '128', '74', '67', '14', '36', '35', '23', '51', '215', '349', 'OutD0']}, 'OutD1': {1: ['OutD1', '23', '47', '150', '51', '74', '67', '14', '217', 'OutD1'], 2: ['OutD1', '144', '172', '128', '35', '36', '150', '47', '51', '28', '266', 'OutD1'], 3: ['OutD1', '349', '266', '47', '14', '67', '150', '35', '129', 'OutD1'], 4: ['OutD1', '172', '35', '150', '128', '14', '23', '51', '47', '28', '266', 'OutD1']}}\n",
      " iterated solution : {'OutD0': {1: ['OutD0', '74', '128', '129', '150', '79', '14', '35', '51', '217', '215', 'OutD0'], 2: ['OutD0', '150', '128', '172', '217', '215', '36', '51', '67', 'OutD0'], 3: ['OutD0', '150', '128', '74', '67', '14', '36', '35', '51', '23', '215', '349', 'OutD0'], 4: ['OutD0', '150', '215', '74', '67', '79', '14', '35', '23', '266', 'OutD0'], 5: ['OutD0', '215', '129', '172', '14', '36', '35', '23', '47', 'OutD0']}, 'OutD1': {1: ['OutD1', '23', '51', '47', '150', '35', '67', '217', '349', 'OutD1'], 2: ['OutD1', '266', '74', '14', '35', '47', '51', '23', '28', '172', '150', 'OutD1'], 3: ['OutD1', '172', '129', '47', '150', '67', '14', '128', '51', '266', '349', 'OutD1'], 4: ['OutD1', '47', '128', '144', '51', '28', '36', '35', '266', 'OutD1']}}\n",
      "local solution makespan: 1076.7730769230766\n",
      " iterated solution makespan : 1023.4423076923076\n",
      "local solution waiting time: 25.234615384615246\n",
      " iterated solution waiting time : 119.81923076923084\n",
      "+-------------------------- END ---------------------------+\n"
     ]
    }
   ],
   "source": [
    " # Local Search:\n",
    "def local_search_solution(iterations = 100):\n",
    "  # initial solution:\n",
    "  solution, _ = initial_solution()\n",
    "  solution_orders = get_batches_of_depots()\n",
    "  solution_makespan, solution_waiting_time = get_makespan(solution, solution_orders)\n",
    "  for i in range(iterations):\n",
    "    # local neighbour solution:\n",
    "    solution_temp = find_neigbour_solution_local(solution)\n",
    "    solution_temp_orders = get_batches_of_depots()\n",
    "    neighbor_makespan_temp, neighbor_waiting_time = get_makespan(solution_temp, solution_temp_orders)\n",
    "    # check if we got a better local neighbour:\n",
    "    if solution_makespan > neighbor_makespan_temp :\n",
    "      solution = solution_temp\n",
    "      solution_makespan = neighbor_makespan_temp\n",
    "      solution_orders = solution_temp_orders\n",
    "      solution_waiting_time = neighbor_waiting_time\n",
    "  return solution , solution_orders ,solution_makespan, solution_waiting_time\n",
    "\n",
    "def iterated_local_search_solution(solution , solution_orders ,solution_makespan,solution_waiting_time, iterations = 100):\n",
    "  solution = solution.copy()\n",
    "  solution_orders = solution_orders.copy()\n",
    "  solution_waiting_time = solution_waiting_time\n",
    "  for i in range(iterations):\n",
    "    # start the perturbation:\n",
    "    solution_temp, solution_temp_orders = find_neigbour_solution_batches(solution)\n",
    "    neighbor_makespan_temp, neighbor_waiting_time = get_makespan(solution_temp, solution_temp_orders)\n",
    "    # take the better solution with less makespan\n",
    "    if solution_makespan > neighbor_makespan_temp :\n",
    "      solution = solution_temp\n",
    "      solution_orders = solution_temp_orders\n",
    "      solution_makespan = neighbor_makespan_temp\n",
    "      solution_waiting_time = neighbor_waiting_time\n",
    "  return solution, solution_orders, solution_makespan, neighbor_waiting_time\n",
    "\n",
    "local_solution , local_solution_orders ,local_solution_makespan, local_solution_waiting_time= local_search_solution(iterations = 10000)\n",
    "ils_solution, ils_solution_orders ,ils_solution_makespan, ils_solution_waiting_time = iterated_local_search_solution(init_solution, init_solution_orders  ,init_solution_makespan,init_solution_waiting_time ,iterations = 10000)\n",
    "\n",
    "print('+------------------------ Local Search RESULTS -------------------------+\\n')\n",
    "\n",
    "print(f'local solution: {local_solution}\\n', f'iterated solution : {ils_solution}')\n",
    "print(f'local solution makespan: {local_solution_makespan}\\n',f'iterated solution makespan : {ils_solution_makespan}')\n",
    "print(f'local solution waiting time: {local_solution_waiting_time}\\n', f'iterated solution waiting time : {ils_solution_waiting_time}')\n",
    "\n",
    "print('+-------------------------- END ---------------------------+')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thqAQst7dV10"
   },
   "source": [
    "# simulated Annealing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdFp5Plzvy7_"
   },
   "source": [
    "## Defining Simualted Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "qnJJNOs7kR8j"
   },
   "outputs": [],
   "source": [
    "class minimize():\n",
    "    def __init__(self, func, solution, solution_orders , find_neigbour_solution, cooling_schedule='linear', step_max=1000, t_min=0, t_max=100, bounds=[], alpha= 0.9, damping=1):\n",
    "\n",
    "        assert cooling_schedule in ['linear','exponential','logarithmic', 'quadratic'], 'cooling_schedule must be either \"linear\", \"exponential\", \"logarithmic\", or \"quadratic\"'\n",
    "\n",
    "        # neighborhood search scheme:\n",
    "        self.find_neigbour_solution = find_neigbour_solution\n",
    "\n",
    "        # initialize starting conditions\n",
    "        self.t = t_max\n",
    "        self.t_max = t_max\n",
    "        self.t_min = t_min\n",
    "        self.step_max = step_max\n",
    "        self.hist = []\n",
    "        self.cooling_schedule = cooling_schedule\n",
    "\n",
    "        self.cost_func = func\n",
    "        self.solution = solution\n",
    "        self.solution_orders = solution_orders\n",
    "        self.bounds = bounds[:]\n",
    "        self.damping = damping\n",
    "        self.current_state = self.solution\n",
    "        self.current_state_orders = self.solution_orders\n",
    "        self.current_energy, self.current_state_waiting_time = func(self.solution, self.solution_orders)\n",
    "        self.best_state = self.current_state\n",
    "        self.best_energy = self.current_energy\n",
    "        self.best_state_orders = self.current_state_orders\n",
    "        self.best_waiting_time = self.current_state_waiting_time\n",
    "\n",
    "\n",
    "        # initialize cooling schedule\n",
    "        if self.cooling_schedule == 'linear':\n",
    "            if alpha != None:\n",
    "                self.update_t = self.cooling_linear_m\n",
    "                self.cooling_schedule = 'linear multiplicative cooling'\n",
    "                self.alpha = alpha\n",
    "\n",
    "            if alpha == None:\n",
    "                self.update_t = self.cooling_linear_a\n",
    "                self.cooling_schedule = 'linear additive cooling'\n",
    "\n",
    "        if self.cooling_schedule == 'quadratic':\n",
    "            if alpha != None:\n",
    "                self.update_t = self.cooling_quadratic_m\n",
    "                self.cooling_schedule = 'quadratic multiplicative cooling'\n",
    "                self.alpha = alpha\n",
    "\n",
    "            if alpha == None:\n",
    "                self.update_t = self.cooling_quadratic_a\n",
    "                self.cooling_schedule = 'quadratic additive cooling'\n",
    "\n",
    "        if self.cooling_schedule == 'exponential':\n",
    "            if alpha == None: self.alpha =  0.8\n",
    "            else: self.alpha = alpha\n",
    "            self.update_t = self.cooling_exponential\n",
    "\n",
    "        if self.cooling_schedule == 'logarithmic':\n",
    "            if alpha == None: self.alpha =  0.8\n",
    "            else: self.alpha = alpha\n",
    "            self.update_t = self.cooling_logarithmic\n",
    "\n",
    "\n",
    "        # begin optimizing\n",
    "        self.step, self.accept = 1, 0\n",
    "        while self.step < self.step_max and self.t >= self.t_min and self.t > 0:\n",
    "            # get neighbor\n",
    "            proposed_neighbor , proposed_orders = self.find_neigbour_solution(self.current_state)\n",
    "\n",
    "            # check energy level of neighbor\n",
    "            E_n, w_t  = self.cost_func(proposed_neighbor, proposed_orders)\n",
    "            dE = (E_n - self.current_energy)\n",
    "                       \n",
    "            # pdb.set_trace()\n",
    "\n",
    "            # determine if we should accept the current neighbor\n",
    "            if random.random() < self.safe_exp(-dE / self.t):\n",
    "                self.current_energy = E_n\n",
    "                self.current_state = proposed_neighbor\n",
    "                self.current_state_orders = proposed_orders\n",
    "                self.current_state_waiting_time = w_t\n",
    "\n",
    "                self.accept += 1\n",
    "\n",
    "            # check if the current neighbor is best solution so far\n",
    "            #pdb.set_trace()\n",
    "            if E_n < self.best_energy:\n",
    "                self.best_energy = E_n\n",
    "                self.best_state = proposed_neighbor\n",
    "                self.best_state_orders = proposed_orders\n",
    "                self.best_waiting_time = w_t\n",
    "\n",
    "            # persist some info for later\n",
    "            self.hist.append([\n",
    "                self.step,\n",
    "                self.t,\n",
    "                self.current_energy,\n",
    "                self.best_energy])\n",
    "\n",
    "            # update some stuff\n",
    "            self.t = self.update_t(self.step)\n",
    "            self.step += 1\n",
    "\n",
    "        # generate some final stats\n",
    "        self.acceptance_rate = self.accept / self.step\n",
    "\n",
    "    def results(self):\n",
    "        print('+------------------------ RESULTS -------------------------+\\n')\n",
    "        print(f'cooling sched.: {self.cooling_schedule}')\n",
    "        if self.damping != 1: print(f'       damping: {self.damping}\\n')\n",
    "        else: print('\\n')\n",
    "\n",
    "        print(f'  initial temp: {self.t_max}')\n",
    "        print(f'    final temp: {self.t:0.6f}')\n",
    "        print(f'     max steps: {self.step_max}')\n",
    "        print(f'    final step: {self.step}\\n')\n",
    "        print(f'    final solution: {self.best_state}\\n')\n",
    "\n",
    "        print(f'  final energy: {self.best_energy:0.6f}\\n')\n",
    "        print(f'  final waiting time: {self.best_waiting_time:0.6f}\\n')\n",
    "        print('+-------------------------- END ---------------------------+')\n",
    "\n",
    "    def get_results(self):\n",
    "      return self.best_state, self.best_state_orders, self.best_energy, self.best_waiting_time\n",
    "\n",
    "    # linear multiplicative cooling\n",
    "    def cooling_linear_m(self, step):\n",
    "        return self.t_max /  (1 + self.alpha * step)\n",
    "\n",
    "    # linear additive cooling\n",
    "    def cooling_linear_a(self, step):\n",
    "        return self.t_min + (self.t_max - self.t_min) * ((self.step_max - step)/self.step_max)\n",
    "\n",
    "    # quadratic multiplicative cooling\n",
    "    def cooling_quadratic_m(self, step):\n",
    "        return self.t_min / (1 + self.alpha * step**2)\n",
    "\n",
    "    # quadratic additive cooling\n",
    "    def cooling_quadratic_a(self, step):\n",
    "        return self.t_min + (self.t_max - self.t_min) * ((self.step_max - step)/self.step_max)**2\n",
    "\n",
    "    # exponential multiplicative cooling\n",
    "    def cooling_exponential(self, step):\n",
    "        return self.t_max * self.alpha**step\n",
    "\n",
    "    # logarithmical multiplicative cooling\n",
    "    def cooling_logarithmic(self, step):\n",
    "        return self.t_max / (self.alpha * log(step + 1))\n",
    "\n",
    "    def safe_exp(self, x):\n",
    "        try: return exp(x)\n",
    "        except: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfYNUtBlp8yq"
   },
   "source": [
    "## getting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJy3kXWR6Kk9"
   },
   "outputs": [],
   "source": [
    "# initial solution:\n",
    "solution_0,_ = initial_solution()\n",
    "solution_0_orders = get_batches_of_depots()\n",
    "# start simulated annealing with specific parameters:\n",
    "sa_minimizer = minimize(get_makespan,\n",
    "                        solution_0,solution_0_orders, cooling_schedule='linear' ,find_neigbour_solution = find_neigbour_solution_batches,\n",
    "                        step_max=10000, t_min=0, t_max=1000, bounds=[], alpha = 0.8 , damping=1)\n",
    "sa_minimizer.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "bMlA1TMsJOoY"
   },
   "outputs": [],
   "source": [
    "  # extracting results from the simulated annealing:\n",
    "sa_solution, sa_solution_orders, sa_solution_makespan, sa_solution_waiting_time = sa_minimizer.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkEc92PgiAEj"
   },
   "source": [
    "# writing to XML:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwPP-vg0eDBx"
   },
   "source": [
    "## functions needed for XML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_K2g804RrSE"
   },
   "outputs": [],
   "source": [
    "def get_order_itemID_podID_letter_color():\n",
    "  order_itemID_podID = get_order_itemID_podID()\n",
    "  order_itemID_letter_color = get_order_itemID_letter_color()\n",
    "  order_itemID_podID_letter_color = {}\n",
    "  for order in order_itemID_podID.keys():\n",
    "    order_itemID_podID_letter_color[order] = {}\n",
    "    for itemID, podID in order_itemID_podID[order].items():\n",
    "      order_itemID_podID_letter_color[order][itemID] = {}\n",
    "      #pdb.set_trace()\n",
    "      order_itemID_podID_letter_color[order][itemID][podID] = order_itemID_letter_color[order][itemID] \n",
    "  return order_itemID_podID_letter_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DB0s7DNcqYW"
   },
   "outputs": [],
   "source": [
    "def get_depot_batch_distance(solution):\n",
    "  batches_of_depots = solution\n",
    "  depot_batch_distance = {}\n",
    "  for depot in batches_of_depots.keys():\n",
    "    depot_batch_distance[depot] = {}\n",
    "    for batchnr, batch in batches_of_depots[depot].items():\n",
    "      distance = 0\n",
    "      for i in range(len(batch) - 1):\n",
    "        distance += distances[(batch[i], batch[i+1] )]\n",
    "      depot_batch_distance[depot][batchnr] =  distance\n",
    "  return depot_batch_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe0UWaUfLFT-"
   },
   "outputs": [],
   "source": [
    "def get_depot_batch_weight_solution(solution_orders):\n",
    "  batches_of_depots = solution_orders\n",
    "  depot_batch_weight = {}\n",
    "  order_weights = get_order_weights()\n",
    "  for depot in batches_of_depots.keys():\n",
    "    depot_batch_weight[depot] = {}\n",
    "    for batchnr, batch in batches_of_depots[depot].items():\n",
    "      weight = 0\n",
    "      for order in batch:\n",
    "        weight += order_weights[order]\n",
    "      depot_batch_weight[depot][batchnr] =  weight\n",
    "  return depot_batch_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsqskvD9mJBZ"
   },
   "outputs": [],
   "source": [
    "# writing the solution to .xml\n",
    "def write_solution_to_xml(solution , solution_orders,solution_makespan,solution_waiting_time, filename):\n",
    "  \n",
    "    # base element\n",
    "    root = ET.Element(\"root\")\n",
    "    # first section \"split\" contains information about which orders are in which batches, and which batches are assigned to which station (=bot)\n",
    "    collecting = ET.SubElement(root, \"Collecting\")\n",
    "    split = ET.SubElement(collecting, 'Split')\n",
    "    #packingStationNames = result.keys()\n",
    "    # write each station as a sub-node of split\n",
    "    for depot in packing_stations:\n",
    "        Bot_ID = ET.SubElement(split, \"Bot\")\n",
    "        Bot_ID.set(\"ID\", depot)\n",
    "        # filter the solution so it only contains batches for the right station\n",
    "        stationSolution = solution[depot]\n",
    "        # write each batch as a sub-node of Bot_ID\n",
    "        for batchID, batch in stationSolution.items():\n",
    "            Batch_ID = ET.SubElement(Bot_ID, \"Batch\")\n",
    "            Batch_ID.set(\"ID\", str(batchID))\n",
    "            # write Orders as the sub-node of Batch_ID\n",
    "            Orders = ET.SubElement(Batch_ID, \"Orders\")\n",
    "            # write each order as sub-node of Batch_ID\n",
    "            for order in solution_orders[depot][batchID]:\n",
    "                order_str = orders_match_ID[order]\n",
    "                Order = ET.SubElement(Orders, \"Order\")\n",
    "                Order.text = order_str\n",
    "                \n",
    "    # first section \"bots\" contains detailed information about each bot (station)\n",
    "    bots = ET.SubElement(collecting, \"Bots\")\n",
    "    # write each station as a sub-node of bots\n",
    "    for depot in packing_stations:\n",
    "        Bot_ID = ET.SubElement(bots, \"Bot\")\n",
    "        Bot_ID.set(\"ID\", depot)\n",
    "        stationSolution = solution[depot]\n",
    "        # batches are written in sub-node Batches of Bot_ID\n",
    "        Batches = ET.SubElement(Bot_ID, \"Batches\")\n",
    "        # write each batch as a sub-node of Bot_ID\n",
    "\n",
    "        for batchID, batch in stationSolution.items():\n",
    "            Batch_ID = ET.SubElement(Batches, \"Batch\")\n",
    "            Batch_ID.set(\"BatchNumber\", str(batchID))\n",
    "\n",
    "            ### need the distance-----------------------\n",
    "            Batch_ID.set(\"Distance\", str(solution_distances[depot][batchID]))\n",
    "            ###------------------------------------------\n",
    "\n",
    "            ### need the weight:-------------------------\n",
    "            Batch_ID.set(\"Weight\", str(batches_weights[depot][batchID]))\n",
    "            ### need the weight--------------------------\n",
    "\n",
    "            # for each batch, write two sub-nodes: itemsData, edges\n",
    "            # first write ItemsData\n",
    "            ItemsData = ET.SubElement(Batch_ID, \"ItemsData\")\n",
    "            # ItemsData has a sub-node called Orders\n",
    "            Orders = ET.SubElement(ItemsData, \"Orders\")\n",
    "            # write each order as sub-node of Orders:\n",
    "            for order in solution_orders[depot][batchID]:\n",
    "                Order = ET.SubElement(Orders, \"Order\")\n",
    "                order_str = orders_match_ID[order]\n",
    "                Order.set(\"ID\", order_str)\n",
    "                # write each item in the order as sub-node of Order\n",
    "                items = items_order_info[order]\n",
    "                for item_ID, item_info in items.items():\n",
    "                    Item = ET.SubElement(Order, \"Item\")\n",
    "                    # for each item, conclude information about the itemID and the description\n",
    "                    Item.set(\"ID\", str(item_ID))\n",
    "                    for pod, c_l in item_info.items():\n",
    "                      Item.set(\"Type\", str(c_l))\n",
    "                      Item.set(\"Pod\", str(pod))\n",
    "         \n",
    "            # write Edges as sub-node of Batch_ID\n",
    "            Edges = ET.SubElement(Batch_ID, \"Edges\")    \n",
    "            # write every edge of the batch\n",
    "            edgeIndex = list(range(0, len(solution[depot][batchID])-1))\n",
    "            for edge in edgeIndex:\n",
    "                Edge = ET.SubElement(Edges, \"Edge\")\n",
    "                Edge.set(\"StartNode\", str(solution[depot][batchID][edge]))\n",
    "                Edge.set(\"EndNode\", str(solution[depot][batchID][edge + 1]))\n",
    "    waiting_time = ET.SubElement(collecting, \"WaitingTime\")\n",
    "    waiting_time.text = str(solution_waiting_time)\n",
    "    makespan = ET.SubElement(collecting, \"Makespan\")\n",
    "    makespan.text = str(solution_makespan)\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akNqAGQyiFGr"
   },
   "outputs": [],
   "source": [
    "# initialising data:\n",
    "orders = orders_list\n",
    "pods = pods_dict\n",
    "order_weights = get_order_weights()\n",
    "items_order_info = get_order_itemID_podID_letter_color()\n",
    "\n",
    "\n",
    "for method in ['greedy','iterated_local_search','simulated_annealing']:\n",
    "  if method == 'greedy':\n",
    "    solution = init_solution\n",
    "    solution_orders = init_solution_orders\n",
    "    solution_makespan = init_solution_makespan\n",
    "    solution_waiting_time = init_solution_waiting_time\n",
    "  elif method == 'iterated_local_search':\n",
    "    solution = ils_solution\n",
    "    solution_orders = ils_solution_orders\n",
    "    solution_makespan = ils_solution_makespan\n",
    "    solution_waiting_time = ils_solution_waiting_time\n",
    "  elif method == 'simulated_annealing':\n",
    "    solution = sa_solution\n",
    "    solution_orders = sa_solution_orders\n",
    "    solution_makespan = sa_solution_makespan\n",
    "    solution_waiting_time = sa_solution_waiting_time\n",
    "  ## get the weights for each batch:\n",
    "  batches_weights = get_depot_batch_weight_solution(solution_orders)\n",
    "  ## get the distances for each batch:\n",
    "  solution_distances = get_depot_batch_distance(solution)\n",
    "  ## specify the output location:\n",
    "  outputName = '/content/drive/MyDrive/AN/results/'+ method + '/orders_' + str(orderAmount) + '_mean_' + str(meanItemInOrder) + '_sku_' + str(itemAmount) + str(orderVersion) + '_solution_dedicated_'+ method + '.xml'\n",
    "  write_solution_to_xml(solution, solution_orders, solution_makespan, solution_waiting_time, outputName)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AN_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
